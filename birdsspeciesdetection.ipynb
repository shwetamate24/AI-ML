{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shwetamate24/AI-ML/blob/main/birdsspeciesdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7Sy_k-IXVEp",
        "outputId": "14e9e571-a719-4661-8fb6-6c0a4e163d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-1c0fa8d6fcb0>:30: FutureWarning: `multichannel` is a deprecated argument name for `hog`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True, multichannel=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.00\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import LinearSVC\n",
        "from skimage.feature import hog\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "\n",
        "# Load images and labels\n",
        "images = []\n",
        "labels = []\n",
        "for i in range(1, 51):\n",
        "  for j in range(1, 11):\n",
        "    img_path = f'/content/drive/MyDrive/archive/test/ABBOTTS BABBLER/1.jpg'\n",
        "    img = cv2.imread(img_path)\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_blur = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
        "    img_thresh = cv2.threshold(img_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    images.append(img_thresh)\n",
        "    labels.append(i)\n",
        "\n",
        "# Convert images and labels to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Extract HOG features from images\n",
        "features = []\n",
        "for image in images:\n",
        "  fd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True, multichannel=False)\n",
        "  features.append(fd)\n",
        "\n",
        "# Convert features to a NumPy array\n",
        "features = np.array(features)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply PCA to reduce the dimensionality of the data to 400 features\n",
        "pca = PCA(n_components=400)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Train the LinearSVC model on the reduced data\n",
        "clf = LinearSVC()\n",
        "clf.fit(X_train_pca, y_train)\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "\n",
        "# Train an SVM classifier on the training data\n",
        "svm = SVC(kernel='linear', C=1)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier on the testing data\n",
        "accuracy = svm.score(X_test, y_test)\n",
        "\n",
        "print(f'Testing accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "model = VGG16(weights='imagenet')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VwqsDAS-uJ20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93be29d6-f058-4d81-cdae-13b3b54bcfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "# Load and preprocess input image\n",
        "input_img = cv2.imread('/content/1.jfif')\n",
        "input_img = cv2.resize(input_img, (224, 224)) # resize to match input size of VGG16\n",
        "input_img = np.expand_dims(input_img, axis=0) # add batch dimension\n",
        "input_img = preprocess_input(input_img) # preprocess using VGG16 preprocessing\n",
        "\n",
        "# Predict bird species label of input image\n",
        "preds = model.predict(input_img)\n",
        "pred_labels = decode_predictions(preds, top=1)[0] # get top 1 predicted labels\n",
        "input_pred_label = pred_labels[0][1]\n",
        "\n",
        "print(f'Input bird species label: {input_pred_label}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "NdgTujQFYDuN",
        "outputId": "94e8bee6-0f14-4959-c1cd-bf0dbef632e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-61082c287d8a>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# resize to match input size of VGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# preprocess using VGG16 preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Predict bird species label of input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocess_input' is not defined"
          ]
        }
      ]
    }
  ]
}